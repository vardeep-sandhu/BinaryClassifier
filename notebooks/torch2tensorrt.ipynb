{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dc05744",
   "metadata": {},
   "source": [
    "This is the torch to tensorrt converter notebook. I will add more stuff once I know what to add. I am following this link: https://learnopencv.com/how-to-convert-a-model-from-pytorch-to-tensorrt-and-speed-up-inference/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ceeaead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "967f737f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_path = \"../runs/traversky/2023_03_05_21_30_33/model.pth\"\n",
    "ONNX_FILE_PATH = 'bin_classifier.onnx'\n",
    "tensorrt_engine_path = \"engine.trt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54d7d4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.fc = nn.Linear(2048, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d932368c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model loaded\n",
    "checkpoint = torch.load(trained_model_path)\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9da74193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de668a4b",
   "metadata": {},
   "source": [
    "Now the tensorrt conversion. \n",
    "\n",
    "First step is to make .onnx file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edcf7cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.empty((1, 3, 256, 256))\n",
    "torch.onnx.export(model, dummy_input, ONNX_FILE_PATH, input_names=['input'],\n",
    "                  output_names=['output'], export_params=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3221cf",
   "metadata": {},
   "source": [
    "Now lets see the tensor rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad1f5663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import numpy as np\n",
    "import tensorrt as trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef9c5add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get logger\n",
    "\n",
    "# def build_engine(onnx_file_path):\n",
    "#     # initialize TensorRT engine and parse ONNX model\n",
    "#     TRT_LOGGER = trt.Logger()\n",
    "#     builder = trt.Builder(TRT_LOGGER)\n",
    "#     network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))\n",
    "#     profile = builder.create_optimization_profile()\n",
    "#     config = builder.create_builder_config()\n",
    "    \n",
    "#     # Setting engine_precesion to FP16\n",
    "#     config.set_flag(trt.BuilderFlag.FP16)\n",
    "    \n",
    "#     # parse ONNX\n",
    "#     parser = trt.OnnxParser(network, TRT_LOGGER)\n",
    "    \n",
    "#     with open(onnx_file_path, 'rb') as model:\n",
    "#         print('Beginning ONNX file parsing')\n",
    "#         parser.parse(model.read())\n",
    "#     print('Completed parsing of ONNX file')\n",
    "#     inputTensor = network.get_input(0)\n",
    "#     print('inputTensor.name:', inputTensor.name)\n",
    "#     network.unmark_output(network.get_output(0))\n",
    "\n",
    "#     print('Building an engine...')\n",
    "#     engineString = builder.build_serialized_network(network, config)\n",
    "#     type(engineString)\n",
    "# #     with open(tensorrt_enginepath, \"wb\") as f:\n",
    "# #         f.write(engineString)\n",
    "     \n",
    "#     #     context = engine.create_execution_context()\n",
    "# #     print(\"Completed creating Engine\")\n",
    " \n",
    "# #     return engine, context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "570edb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "def build_engine(onnx_path, shape = [1,224,224,3]):\n",
    "\n",
    "   \"\"\"\n",
    "   This is the function to create the TensorRT engine\n",
    "   Args:\n",
    "      onnx_path : Path to onnx_file. \n",
    "      shape : Shape of the input of the ONNX file. \n",
    "  \"\"\"\n",
    "   with trt.Builder(TRT_LOGGER) as builder, builder.create_network(1) as network, builder.create_builder_config() as config, trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "       config.max_workspace_size = (256 << 20)\n",
    "       with open(onnx_path, 'rb') as model:\n",
    "           parser.parse(model.read())\n",
    "       network.get_input(0).shape = shape\n",
    "       engine = builder.build_engine(network, config)\n",
    "       return engine\n",
    "\n",
    "def save_engine(engine, file_name):\n",
    "   buf = engine.serialize()\n",
    "   with open(file_name, 'wb') as f:\n",
    "       f.write(buf)\n",
    "\n",
    "def load_engine(trt_runtime, plan_path):\n",
    "   with open(plan_path, 'rb') as f:\n",
    "       engine_data = f.read()\n",
    "   engine = trt_runtime.deserialize_cuda_engine(engine_data)\n",
    "   return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3e1d722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06/12/2023-12:26:12] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage. See `CUDA_MODULE_LOADING` in https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18519/2683552468.py:11: DeprecationWarning: Use set_memory_pool_limit instead.\n",
      "  config.max_workspace_size = (256 << 20)\n",
      "/tmp/ipykernel_18519/2683552468.py:15: DeprecationWarning: Use build_serialized_network instead.\n",
      "  engine = builder.build_engine(network, config)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06/12/2023-12:26:13] [TRT] [W] TensorRT was linked against cuDNN 8.6.0 but loaded cuDNN 8.3.2\n",
      "[06/12/2023-12:26:24] [TRT] [W] TensorRT was linked against cuDNN 8.6.0 but loaded cuDNN 8.3.2\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import tensorrt as trt \n",
    "\n",
    "engine_name = \"resnet50.plan\"\n",
    "batch_size = 1 \n",
    "\n",
    "shape = [batch_size , 3, 256 ,256]\n",
    "engine = build_engine(ONNX_FILE_PATH, shape= shape)\n",
    "save_engine(engine, engine_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4674fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
